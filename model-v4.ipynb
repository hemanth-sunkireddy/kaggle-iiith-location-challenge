{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemanth-sunkireddy/kaggle-iiith-location-challenge/blob/main/model-v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQHY1KN-pe7K"
      },
      "outputs": [],
      "source": [
        "# !pip install torch torchvision --force-reinstall\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!cp -r /content/drive/MyDrive/SMAI_Project/SMAI_Project/images_train /content/\n",
        "!cp -r /content/drive/MyDrive/SMAI_Project/SMAI_Project/images_val /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8FBQzH3FHW3"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/SMAI_Project/SMAI_Project/labels_train.csv /content/\n",
        "!cp -r /content/drive/MyDrive/SMAI_Project/SMAI_Project/labels_val.csv /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv_path = 'labels_train.csv'\n",
        "val_csv_path = 'labels_val.csv'\n",
        "train_img_dir = '/content/images_train'\n",
        "val_img_dir = '/content/images_val'\n",
        "lat_long_output_csv = '/content/lat-long.csv'\n",
        "region_output_csv = '/content/region.csv'\n",
        "angle_output_csv = '/content/angle.csv'"
      ],
      "metadata": {
        "id": "z73ELKuuN9GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms, models"
      ],
      "metadata": {
        "id": "x0cN31dXOPLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üíª Using device: {device}\")"
      ],
      "metadata": {
        "id": "6wDNyDGBOffb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_csv_path)\n",
        "val_df = pd.read_csv(val_csv_path)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "pzFfbpSkU6EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Region Prediction"
      ],
      "metadata": {
        "id": "1XB-H4fbPDo-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq7Yv_1i_slm"
      },
      "outputs": [],
      "source": [
        "class RegionDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        print(f\"üì¶ Initialized dataset with {len(self.df)} samples from {img_dir}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = row['Region_ID'] - 1  # 0-indexed\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "train_dataset = RegionDataset(train_df, train_img_dir, train_transform)\n",
        "val_dataset = RegionDataset(val_df, val_img_dir, val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Fine-tune entire model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, 15)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "epochs = 15\n",
        "best_val_acc = 0\n",
        "\n",
        "print(\"üö¶ Starting training...\")\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    pbar = tqdm(train_loader, desc=f\"üìö Epoch {epoch+1}/{epochs}\", leave=False)\n",
        "\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        pbar.set_postfix({'Loss': f\"{running_loss / (pbar.n + 1):.4f}\"})\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # -------------------------\n",
        "    # Validation Accuracy\n",
        "    # -------------------------\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    ground_truth = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            ground_truth.extend(labels.numpy())\n",
        "\n",
        "    val_acc = accuracy_score(ground_truth, predictions)\n",
        "    print(f\"‚úÖ Epoch {epoch+1} | Loss: {avg_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    # Save best model (optional)\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), os.path.join(base_path, 'best_model.pth'))\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "print(\"üîç Final evaluation on validation set...\")\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in val_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        predictions.extend(preds.cpu().numpy())\n",
        "\n",
        "val_preds_df = pd.DataFrame({\n",
        "    'id': list(range(369)),\n",
        "    'Region_ID': [p + 1 for p in predictions]\n",
        "})\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id': list(range(369, 738)),\n",
        "    'Region_ID': [1] * 369\n",
        "})\n",
        "\n",
        "submission_df = pd.concat([val_preds_df, test_df], ignore_index=True)\n",
        "submission_df.to_csv(region_output_csv, index=False)\n",
        "print(f\"üìÅ Submission saved to {region_output_csv}\")\n",
        "print(\"üéâ All steps completed. Best Validation Accuracy: {:.4f}\".format(best_val_acc))\n"
      ],
      "metadata": {
        "id": "KYFEAWS3cMau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Angle Prediction"
      ],
      "metadata": {
        "id": "QD2M8oi3PL5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7kPZWVEDoN8"
      },
      "outputs": [],
      "source": [
        "class AngleDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        angle = row['angle']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, angle\n",
        "\n",
        "def mean_absolute_angular_error(true, pred):\n",
        "    true = np.array(true)\n",
        "    pred = np.array(pred)\n",
        "    return np.mean(np.minimum(np.abs(true - pred), 360 - np.abs(true - pred)))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 1)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "best_maae = float('inf')\n",
        "\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, angles in tqdm(train_loader, desc=f\"üìö Epoch {epoch+1}/100\"):\n",
        "        images = images.to(device)\n",
        "        angles = angles.float().unsqueeze(1).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, angles)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"‚úÖ Epoch {epoch+1}: Loss = {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_preds = []\n",
        "    val_gts = []\n",
        "    with torch.no_grad():\n",
        "        for images, angles in val_loader:\n",
        "            images = images.to(device)\n",
        "            angles = angles.numpy()\n",
        "            outputs = model(images).cpu().numpy().flatten()\n",
        "            val_preds.extend(outputs)\n",
        "            val_gts.extend(angles)\n",
        "\n",
        "    val_preds_clamped = [round(max(0, min(360, p))) for p in val_preds]\n",
        "    maae_score = mean_absolute_angular_error(val_gts, val_preds_clamped)\n",
        "    print(f\"üéØ Epoch {epoch+1}: Validation MAAE = {maae_score:.2f} degrees\")\n",
        "\n",
        "    if maae_score < best_maae:\n",
        "        best_maae = maae_score\n",
        "        val_submission = pd.DataFrame({\n",
        "            'id': list(range(len(val_preds_clamped))),\n",
        "            'angle': val_preds_clamped\n",
        "        })\n",
        "        dummy_test_submission = pd.DataFrame({\n",
        "            'id': list(range(len(val_preds_clamped), 738)),\n",
        "            'angle': [0] * (738 - len(val_preds_clamped))\n",
        "        })\n",
        "        final_submission = pd.concat([val_submission, dummy_test_submission], ignore_index=True)\n",
        "        final_submission.to_csv(lat_long_output_csv, index=False)\n",
        "        print(f\"üíæ Best MAAE improved to {best_maae:.2f}, submission saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvPSERbgLUI8"
      },
      "outputs": [],
      "source": [
        "anomaly_ids = [95, 145, 146, 158, 159, 160, 161]\n",
        "val_df = val_df[~val_df.index.isin(anomaly_ids)].reset_index(drop=True)\n",
        "\n",
        "class GeoDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        target = torch.tensor([row['latitude'], row['longitude']], dtype=torch.float)\n",
        "        return image, target, row['filename']\n",
        "\n",
        "# üì¶ Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# üîÑ Dataloaders\n",
        "train_dataset = GeoDataset(train_df, train_img_dir, transform=train_transform)\n",
        "val_dataset = GeoDataset(val_df, val_img_dir, transform=val_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "\n",
        "# üß† Model & Optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = efficientnet_b0(pretrained=True)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
        "\n",
        "# üìâ Track best model\n",
        "best_val_mse = float('inf')\n",
        "\n",
        "# üèãÔ∏è‚Äç‚ôÇÔ∏è Training Loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for images, targets, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        images, targets = images.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # üìä Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for images, targets, filenames in val_loader:\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            # Save predictions for CSV\n",
        "            for fname, pred in zip(filenames, outputs.cpu().numpy()):\n",
        "                predictions.append({'filename': fname, 'latitude': pred[0], 'longitude': pred[1]})\n",
        "\n",
        "    val_mse = val_loss / len(val_loader)\n",
        "    print(f\"‚úÖ Epoch {epoch+1} - Train Loss: {train_loss:.4f} | Val MSE: {val_mse:.4f}\")\n",
        "\n",
        "    # üíæ Save best predictions\n",
        "    if val_mse < best_val_mse:\n",
        "        best_val_mse = val_mse\n",
        "        print(f\"üåü New best MSE: {best_val_mse:.4f}, saving predictions.\")\n",
        "        pd.DataFrame(predictions).to_csv(output_csv, index=False)\n",
        "\n",
        "\n",
        "\n",
        "# ‚ùå Remove anomaly IDs from val and preserve original indices\n",
        "anomaly_ids = [95, 145, 146, 158, 159, 160, 161]\n",
        "val_df_cleaned = val_df.drop(anomaly_ids).reset_index(drop=False)  # Keep original index as 'index'\n",
        "val_df_cleaned.rename(columns={'index': 'id'}, inplace=True)       # Rename index to 'id'\n",
        "\n",
        "# ...\n",
        "# üìà Validation\n",
        "model.eval()\n",
        "val_preds = []\n",
        "with torch.no_grad():\n",
        "    for images, _ in val_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.round().cpu().numpy().astype(int)\n",
        "        val_preds.extend(preds)\n",
        "\n",
        "# üì§ Submission file\n",
        "print(\"üìù Generating submission...\")\n",
        "val_submission = pd.DataFrame({\n",
        "    'id': val_df_cleaned['id'].tolist(),  # Use original id\n",
        "    'Latitude': [lat for lat, lon in val_preds],\n",
        "    'Longitude': [lon for lat, lon in val_preds]\n",
        "})\n",
        "\n",
        "# Add 0,0 for test samples\n",
        "test_ids = list(range(369, 738))\n",
        "test_submission = pd.DataFrame({\n",
        "    'id': test_ids,\n",
        "    'Latitude': [0] * len(test_ids),\n",
        "    'Longitude': [0] * len(test_ids)\n",
        "})\n",
        "\n",
        "# Combine and save\n",
        "submission_df = pd.concat([val_submission, test_submission], ignore_index=True)\n",
        "submission_df = submission_df.sort_values(by='id').reset_index(drop=True)\n",
        "submission_df.to_csv('2022101005_1.csv', index=False)\n",
        "print(\"‚úÖ Submission file '2022101005_1.csv' created!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}