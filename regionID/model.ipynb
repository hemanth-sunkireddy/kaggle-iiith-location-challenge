{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8468e58f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install torch torchvision --force-reinstall\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_train /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_val /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_test /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/labels_train.csv /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/labels_val.csv /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4801a92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "val_csv_path = 'labels_val.csv'\n",
    "train_csv_path = '/content/labels_train.csv'\n",
    "train_img_dir = '/content/images_train'\n",
    "val_img_dir = '/content/images_val'\n",
    "lat_long_output_csv = '/content/lat-long.csv'\n",
    "region_output_csv = '/content/region.csv'\n",
    "angle_output_csv = '/content/angle.csv'\n",
    "test_img_dir = '/content/images_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07f671",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf894c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üíª Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca73dc2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb1f43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class RegionDataset(Dataset):\n",
    "    def __init__(self, img_dir, df=None, transform=None, is_test=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "        if not is_test:\n",
    "            self.df = df.reset_index(drop=True)\n",
    "            self.filenames = self.df['filename'].tolist()\n",
    "            print(f\"Initialized dataset with {len(self.df)} samples from {img_dir}\")\n",
    "        else:\n",
    "            self.filenames = sorted([\n",
    "                f for f in os.listdir(img_dir)\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "            ])\n",
    "            print(f\"Initialized test dataset with {len(self.filenames)} images from {img_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, filename  # No label\n",
    "        else:\n",
    "            label = self.df.iloc[idx]['Region_ID'] - 1\n",
    "            return image, label, filename\n",
    "\n",
    "train_dataset = RegionDataset(train_img_dir, df=train_df, transform=train_transform)\n",
    "val_dataset = RegionDataset(val_img_dir, df=val_df, transform=val_transform)\n",
    "\n",
    "test_dataset = RegionDataset(test_img_dir, transform=test_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=2, pin_memory=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c6ff8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.fc = nn.Linear(model.fc.in_features, 15)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "patience = 4\n",
    "region_vectors = {}\n",
    "\n",
    "print(\"üö¶ Starting training with early stopping...\")\n",
    "for epoch in range(20):  # Max 20 epochs\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"üìö Epoch {epoch+1}/20\", leave=False)\n",
    "    for images, labels, filenames in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'Loss': f\"{running_loss / (pbar.n + 1):.4f}\"})\n",
    "\n",
    "        # Collect region IDs for train samples\n",
    "        for fname, label in zip(filenames, labels.cpu().numpy()):\n",
    "            region_vectors[fname] = label + 1  # back to 1-indexed\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    predictions, ground_truth = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            ground_truth.extend(labels.numpy())\n",
    "\n",
    "    val_acc = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch - best_epoch >= patience:\n",
    "        print(f\"‚èπ Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, \"best_region_model.pth\")\n",
    "    print(f\"Saved best model from epoch {best_epoch+1} with val acc: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b06c41",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, _, _ in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "val_preds_df = pd.DataFrame({\n",
    "    'id': list(range(369)),\n",
    "    'Region_ID': [p + 1 for p in predictions]\n",
    "})\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, filenames in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "        test_filenames.extend(filenames)\n",
    "\n",
    "test_preds_df = pd.DataFrame({\n",
    "    'id': list(range(369, 738)),\n",
    "    'Region_ID': [p + 1 for p in test_predictions]\n",
    "})\n",
    "\n",
    "submission_df = pd.concat([val_preds_df, test_preds_df], ignore_index=True)\n",
    "submission_df.to_csv(region_output_csv, index=False)\n",
    "print(f\"Region submission saved to {region_output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
