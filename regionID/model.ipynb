{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c53f842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:10:37.429229Z",
     "iopub.status.busy": "2025-05-04T20:10:37.428976Z",
     "iopub.status.idle": "2025-05-04T20:10:37.436659Z",
     "shell.execute_reply": "2025-05-04T20:10:37.435825Z"
    },
    "papermill": {
     "duration": 0.01382,
     "end_time": "2025-05-04T20:10:37.437822",
     "exception": false,
     "start_time": "2025-05-04T20:10:37.424002",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iiit-hyd-smai-project-dataset/labels_val.csv\n"
     ]
    }
   ],
   "source": [
    "val_csv_path = '/kaggle/input/iiit-hyd-smai-project-dataset/labels_val.csv'\n",
    "train_csv_path = '/kaggle/input/iiit-hyd-smai-project-dataset/labels_train.csv'\n",
    "train_img_dir = '/kaggle/input/iiit-hyd-smai-project-dataset/images_train'\n",
    "val_img_dir = '/kaggle/input/iiit-hyd-smai-project-dataset/images_val'\n",
    "test_img_dir = '/kaggle/input/iiit-hyd-smai-project-dataset/images_test'\n",
    "\n",
    "# Output files will be written to the working directory\n",
    "lat_long_output_csv = '/kaggle/working/lat-long.csv'\n",
    "region_output_csv = '/kaggle/working/region.csv'\n",
    "angle_output_csv = '/kaggle/working/angle.csv'\n",
    "print(val_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103011a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:10:37.442855Z",
     "iopub.status.busy": "2025-05-04T20:10:37.442358Z",
     "iopub.status.idle": "2025-05-04T20:11:03.204208Z",
     "shell.execute_reply": "2025-05-04T20:11:03.203526Z"
    },
    "papermill": {
     "duration": 25.765904,
     "end_time": "2025-05-04T20:11:03.205870",
     "exception": false,
     "start_time": "2025-05-04T20:10:37.439966",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 186MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e8d173a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:11:03.213691Z",
     "iopub.status.busy": "2025-05-04T20:11:03.212986Z",
     "iopub.status.idle": "2025-05-04T20:11:03.319051Z",
     "shell.execute_reply": "2025-05-04T20:11:03.318348Z"
    },
    "papermill": {
     "duration": 0.111257,
     "end_time": "2025-05-04T20:11:03.320218",
     "exception": false,
     "start_time": "2025-05-04T20:11:03.208961",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üíª Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96bce9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:11:03.326529Z",
     "iopub.status.busy": "2025-05-04T20:11:03.326285Z",
     "iopub.status.idle": "2025-05-04T20:11:03.394623Z",
     "shell.execute_reply": "2025-05-04T20:11:03.393678Z"
    },
    "papermill": {
     "duration": 0.073197,
     "end_time": "2025-05-04T20:11:03.396328",
     "exception": false,
     "start_time": "2025-05-04T20:11:03.323131",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17439aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:11:03.403384Z",
     "iopub.status.busy": "2025-05-04T20:11:03.402694Z",
     "iopub.status.idle": "2025-05-04T20:11:03.441655Z",
     "shell.execute_reply": "2025-05-04T20:11:03.440796Z"
    },
    "papermill": {
     "duration": 0.043635,
     "end_time": "2025-05-04T20:11:03.442897",
     "exception": false,
     "start_time": "2025-05-04T20:11:03.399262",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 6542 samples from /kaggle/input/iiit-hyd-smai-project-dataset/images_train\n",
      "Initialized dataset with 369 samples from /kaggle/input/iiit-hyd-smai-project-dataset/images_val\n",
      "Initialized test dataset with 369 images from /kaggle/input/iiit-hyd-smai-project-dataset/images_test\n"
     ]
    }
   ],
   "source": [
    "class RegionDataset(Dataset):\n",
    "    def __init__(self, img_dir, df=None, transform=None, is_test=False):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "        if not is_test:\n",
    "            self.df = df.reset_index(drop=True)\n",
    "            self.filenames = self.df['filename'].tolist()\n",
    "            print(f\"Initialized dataset with {len(self.df)} samples from {img_dir}\")\n",
    "        else:\n",
    "            self.filenames = sorted([\n",
    "                f for f in os.listdir(img_dir)\n",
    "                if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "            ])\n",
    "            print(f\"Initialized test dataset with {len(self.filenames)} images from {img_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, filename  # No label\n",
    "        else:\n",
    "            label = self.df.iloc[idx]['Region_ID'] - 1\n",
    "            return image, label, filename\n",
    "\n",
    "train_dataset = RegionDataset(train_img_dir, df=train_df, transform=train_transform)\n",
    "val_dataset = RegionDataset(val_img_dir, df=val_df, transform=val_transform)\n",
    "\n",
    "test_dataset = RegionDataset(test_img_dir, transform=test_transform, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=2, pin_memory=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7487330d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:11:03.448839Z",
     "iopub.status.busy": "2025-05-04T20:11:03.448607Z",
     "iopub.status.idle": "2025-05-04T20:24:51.991241Z",
     "shell.execute_reply": "2025-05-04T20:24:51.990468Z"
    },
    "papermill": {
     "duration": 828.547257,
     "end_time": "2025-05-04T20:24:51.992636",
     "exception": false,
     "start_time": "2025-05-04T20:11:03.445379",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö¶ Starting training with early stopping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 2.6167 | Validation Accuracy: 0.1653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 2.4867 | Validation Accuracy: 0.2385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 2.3879 | Validation Accuracy: 0.2818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 2.3017 | Validation Accuracy: 0.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 2.2325 | Validation Accuracy: 0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 2.1706 | Validation Accuracy: 0.4092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 2.1185 | Validation Accuracy: 0.4065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 2.0739 | Validation Accuracy: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 2.0288 | Validation Accuracy: 0.4553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 1.9959 | Validation Accuracy: 0.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 1.9736 | Validation Accuracy: 0.4743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 1.9724 | Validation Accuracy: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 1.9689 | Validation Accuracy: 0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 1.9575 | Validation Accuracy: 0.4715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 1.9620 | Validation Accuracy: 0.4661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 1.9573 | Validation Accuracy: 0.4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 1.9506 | Validation Accuracy: 0.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 1.9518 | Validation Accuracy: 0.5014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 1.9468 | Validation Accuracy: 0.4770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 1.9406 | Validation Accuracy: 0.4688\n",
      "Saved best model from epoch 18 with val acc: 0.5014\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "model.fc = nn.Linear(model.fc.in_features, 15)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "patience = 4\n",
    "region_vectors = {}\n",
    "\n",
    "print(\"üö¶ Starting training with early stopping...\")\n",
    "for epoch in range(20):  # Max 20 epochs\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    pbar = tqdm(train_loader, desc=f\"üìö Epoch {epoch+1}/20\", leave=False)\n",
    "    for images, labels, filenames in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'Loss': f\"{running_loss / (pbar.n + 1):.4f}\"})\n",
    "\n",
    "        # Collect region IDs for train samples\n",
    "        for fname, label in zip(filenames, labels.cpu().numpy()):\n",
    "            region_vectors[fname] = label + 1  # back to 1-indexed\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    predictions, ground_truth = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            ground_truth.extend(labels.numpy())\n",
    "\n",
    "    val_acc = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Validation Accuracy: {val_acc:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch - best_epoch >= patience:\n",
    "        print(f\"‚èπ Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    torch.save(best_model_state, \"/kaggle/working/best_region_model.pth\")\n",
    "    print(f\"Saved best model from epoch {best_epoch+1} with val acc: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "385dbfe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T20:24:52.385084Z",
     "iopub.status.busy": "2025-05-04T20:24:52.384323Z",
     "iopub.status.idle": "2025-05-04T20:24:57.283310Z",
     "shell.execute_reply": "2025-05-04T20:24:57.282280Z"
    },
    "papermill": {
     "duration": 5.119706,
     "end_time": "2025-05-04T20:24:57.284463",
     "exception": false,
     "start_time": "2025-05-04T20:24:52.164757",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region submission saved to /kaggle/working/region.csv\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, _, _ in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "val_preds_df = pd.DataFrame({\n",
    "    'id': list(range(369)),\n",
    "    'Region_ID': [p + 1 for p in predictions]\n",
    "})\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, filenames in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_predictions.extend(preds.cpu().numpy())\n",
    "        test_filenames.extend(filenames)\n",
    "\n",
    "test_preds_df = pd.DataFrame({\n",
    "    'id': list(range(369, 738)),\n",
    "    'Region_ID': [p + 1 for p in test_predictions]\n",
    "})\n",
    "\n",
    "submission_df = pd.concat([val_preds_df, test_preds_df], ignore_index=True)\n",
    "submission_df.to_csv(region_output_csv, index=False)\n",
    "print(f\"Region submission saved to {region_output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7328559,
     "sourceId": 11676657,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 233850374,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 869.559814,
   "end_time": "2025-05-04T20:25:01.218059",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-04T20:10:31.658245",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
