{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d52f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision --force-reinstall\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_train /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_val /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/images_test /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/labels_train.csv /content/\n",
    "!cp -r /content/drive/MyDrive/SMAI_Project/labels_val.csv /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a392b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv_path = 'labels_val.csv'\n",
    "train_csv_path = '/content/labels_train.csv'\n",
    "train_img_dir = '/content/images_train'\n",
    "val_img_dir = '/content/images_val'\n",
    "lat_long_output_csv = '/content/lat-long.csv'\n",
    "region_output_csv = '/content/region.csv'\n",
    "angle_output_csv = '/content/angle.csv'\n",
    "test_img_dir = '/content/images_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7394558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4bdfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ’» Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5083bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompassDataset(Dataset):\n",
    "    def __init__(self, img_dir, csv_path, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        angles_rad = np.deg2rad(self.df['angle'].astype(float).values)\n",
    "        self.sin_targets = np.sin(angles_rad)\n",
    "        self.cos_targets = np.cos(angles_rad)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['filename'])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = torch.tensor([self.sin_targets[idx], self.cos_targets[idx]], dtype=torch.float32)\n",
    "        return image, target\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = sorted(os.listdir(img_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CompassDataset(train_img_dir, train_csv_path, transform=train_transform)\n",
    "val_dataset = CompassDataset(val_img_dir, val_csv_path, transform=val_transform)\n",
    "test_dataset = TestDataset(test_img_dir, transform=val_transform)\n",
    "print(train_csv_path)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80512c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features, 2)\n",
    "if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "def circular_mae(pred, target):\n",
    "    ang_pred = torch.atan2(pred[:, 0], pred[:, 1]) * (180.0 / np.pi)\n",
    "    ang_true = torch.atan2(target[:, 0], target[:, 1]) * (180.0 / np.pi)\n",
    "    diff = torch.abs(ang_pred - ang_true)\n",
    "    return torch.min(diff, 360.0 - diff).mean()\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, tgt in loader:\n",
    "            imgs, tgt = imgs.to(device, non_blocking=True), tgt.to(device, non_blocking=True)\n",
    "            preds = model(imgs)\n",
    "            total_loss += circular_mae(preds, tgt).item() * imgs.size(0)\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_trainable_layers(model, train_head_only=True):\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = True if not train_head_only else ('classifier' in name)\n",
    "\n",
    "def get_optimizer(model, lr):\n",
    "    params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
    "    return torch.optim.Adam(params_to_update, lr=lr)\n",
    "\n",
    "def process_batch(model, imgs, tgt, device):\n",
    "    imgs, tgt = imgs.to(device), tgt.to(device)\n",
    "    with torch.cuda.amp.autocast():\n",
    "        preds = model(imgs)\n",
    "        loss_batch = circular_mae(preds, tgt)\n",
    "    return preds, loss_batch\n",
    "\n",
    "\n",
    "def calculate_loss_and_backward(loss_batch, scaler, optimizer, batch_accum):\n",
    "    loss = loss_batch / batch_accum\n",
    "    scaler.scale(loss).backward()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def manage_optimizer_step(step, scaler, optimizer, batch_accum):\n",
    "    if (step + 1) % batch_accum == 0:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device, batch_accum, desc=\"Training\"):\n",
    "    model.train()\n",
    "    loop = iter(tqdm(loader, desc=desc))\n",
    "    step = 0\n",
    "    total_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            imgs, tgt = next(loop)\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "\n",
    "        preds, loss_batch = process_batch(model, imgs, tgt, device)\n",
    "        loss = calculate_loss_and_backward(loss_batch, scaler, optimizer, batch_accum)\n",
    "        manage_optimizer_step(step, scaler, optimizer, batch_accum)\n",
    "        \n",
    "        step += 1\n",
    "        total_loss += loss_batch.item() * imgs.size(0)\n",
    "        tqdm.write(f\"Loss: {loss_batch.item():.4f}\")\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def save_best_model(model, val_loss, best_loss, best_state_dict, path='best_model.pt'):\n",
    "    if val_loss >= best_loss:\n",
    "        return best_loss, best_state_dict\n",
    "    best_state_dict = model.state_dict()\n",
    "    torch.save(best_state_dict, path)\n",
    "    print(f\"Saved best model with Val MAE: {val_loss:.2f}Â° â†’ {path}\")\n",
    "    return val_loss, best_state_dict\n",
    "\n",
    "\n",
    "def train_head(model, train_loader, val_loader, device, head_epochs, head_lr, batch_accum, patience):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    best_loss = float('inf')\n",
    "    best_state_dict = None\n",
    "    optimizer = get_optimizer(model, head_lr)\n",
    "    \n",
    "    epoch = 0\n",
    "    while epoch < head_epochs:\n",
    "        train_mae = train_one_epoch(model, train_loader, optimizer, scaler, device, batch_accum, desc=f\"Head Epoch {epoch+1}/{head_epochs}\")\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "        print(f\"â†’ [Head] Train MAE: {train_mae:.2f}Â°, Val MAE: {val_loss:.2f}Â°\")\n",
    "        best_loss, best_state_dict = save_best_model(model, val_loss, best_loss, best_state_dict)\n",
    "        epoch += 1\n",
    "        \n",
    "    return best_loss, best_state_dict\n",
    "\n",
    "\n",
    "def fine_tune(model, train_loader, val_loader, device, ft_epochs, ft_lr, batch_accum, patience, best_loss, best_state_dict):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    optimizer = get_optimizer(model, ft_lr)\n",
    "    \n",
    "    epoch = 0\n",
    "    while epoch < ft_epochs:\n",
    "        train_mae = train_one_epoch(model, train_loader, optimizer, scaler, device, batch_accum, desc=f\"FT Epoch {epoch+1}/{ft_epochs}\")\n",
    "        val_loss = evaluate(model, val_loader, device)\n",
    "        print(f\"â†’ [FT] Train MAE: {train_mae:.2f}Â°, Val MAE: {val_loss:.2f}Â°\")\n",
    "        best_loss, best_state_dict = save_best_model(model, val_loss, best_loss, best_state_dict)\n",
    "        epoch += 1\n",
    "        \n",
    "    return best_loss, best_state_dict\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, head_epochs=10, ft_epochs=50, head_lr=1e-3, ft_lr=1e-4, batch_accum=2, patience=5):\n",
    "    # Head Training\n",
    "    set_trainable_layers(model, train_head_only=True)\n",
    "    best_loss, best_state_dict = train_head(model, train_loader, val_loader, device, head_epochs, head_lr, batch_accum, patience)\n",
    "    \n",
    "    # Fine-Tuning\n",
    "    set_trainable_layers(model, train_head_only=False)\n",
    "    best_loss, best_state_dict = fine_tune(model, train_loader, val_loader, device, ft_epochs, ft_lr, batch_accum, patience, best_loss, best_state_dict)\n",
    "    \n",
    "    # Load the best model after training\n",
    "    model.load_state_dict(best_state_dict) if best_state_dict else print(\"No model was saved (no improvement observed during training).\")\n",
    "\n",
    "\n",
    "train_model(model, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_angles_from_output(preds):\n",
    "    \"\"\"Convert sine and cosine predictions to angles in degrees.\"\"\"\n",
    "    sin = preds[:, 0]\n",
    "    cos = preds[:, 1]\n",
    "    ang = torch.atan2(sin, cos) * (180.0 / np.pi)\n",
    "    return ang % 360\n",
    "\n",
    "def summarize_angles(angles):\n",
    "    \"\"\"Print basic statistics about predicted angles.\"\"\"\n",
    "    print(f\"ðŸ“Š Angle Stats â†’ Min: {min(angles):.2f}Â°, Max: {max(angles):.2f}Â°, Mean: {np.mean(angles):.2f}Â°\")\n",
    "\n",
    "def save_angles_to_csv(angles, path):\n",
    "    \"\"\"Save predicted angles to a CSV file for debugging or analysis.\"\"\"\n",
    "    df = pd.DataFrame({\"angle\": angles})\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"ðŸ“ Debug angles saved to {path}\")\n",
    "\n",
    "def predict_angles(model, loader, device, return_raw=False, verbose=False, save_csv=False, csv_path=\"debug_angles.csv\"):\n",
    "    \"\"\"Run inference and predict angles from a model.\"\"\"\n",
    "    model.eval()\n",
    "    preds_final = []\n",
    "    sin_cos_raw = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            imgs = batch[0] if isinstance(batch, (tuple, list)) else batch\n",
    "            imgs = imgs.to(device)\n",
    "            preds = model(imgs)\n",
    "            angles = compute_angles_from_output(preds).cpu().numpy().tolist()\n",
    "            preds_final.extend(angles)\n",
    "            if return_raw:\n",
    "                sin_cos_raw.extend(preds.cpu().numpy().tolist())\n",
    "            if verbose:\n",
    "                print(f\"Batch {i+1}: Angles = {[round(a, 2) for a in angles]}\")\n",
    "\n",
    "    summarize_angles(preds_final)\n",
    "\n",
    "    if save_csv:\n",
    "        save_angles_to_csv(preds_final, csv_path)\n",
    "\n",
    "    return (preds_final, sin_cos_raw) if return_raw else preds_final\n",
    "\n",
    "def create_submission_csv(angles, output_csv):\n",
    "    \"\"\"Create submission file from predicted angles.\"\"\"\n",
    "    all_preds = [int(round(x)) for x in angles]\n",
    "    ids = list(range(len(all_preds)))\n",
    "    df = pd.DataFrame({\"id\": ids, \"angle\": all_preds})\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved submission with {len(df)} rows to {output_csv}\")\n",
    "\n",
    "def generate_submission(model, val_loader, test_loader, device, output_csv=\"YourRollNo_1.csv\", verbose=False):\n",
    "    \"\"\"Load the best model and generate submission from validation + test predictions.\"\"\"\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\", map_location=device))\n",
    "    \n",
    "    print(\"ðŸ“¦ Predicting on validation data...\")\n",
    "    val_preds = predict_angles(model, val_loader, device, verbose=verbose)\n",
    "\n",
    "    print(\"ðŸ“¦ Predicting on test data...\")\n",
    "    test_preds = predict_angles(model, test_loader, device, verbose=verbose)\n",
    "\n",
    "    all_preds = val_preds + test_preds\n",
    "    create_submission_csv(all_preds, output_csv)\n",
    "\n",
    "generate_submission(model, val_loader, test_loader, device, output_csv='2022101001_5.csv', verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
